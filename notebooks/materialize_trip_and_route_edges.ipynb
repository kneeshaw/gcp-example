{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89bc079",
   "metadata": {},
   "source": [
    "> Tip: Run the shapes_geog materialization first if the table doesn't exist or is stale. A helper cell to run it is included below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e504b",
   "metadata": {},
   "source": [
    "# Materialize Trip and Route Edges\n",
    "This notebook lets you set variables and run the parameterized BigQuery SQL in `infrastructure/queries/scheduled/` to:\n",
    "- Reset the `trip_edges` table schema\n",
    "- Insert `trip_edges` for a specific `route_id` (or by shards)\n",
    "- Build the aggregated `route_edges` table\n",
    " \n",
    "It uses Application Default Credentials (ADC) or a service account if configured. Ensure you have access to the target project and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a435b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (optional; uncomment if needed)\n",
    "# %pip install -q google-cloud-bigquery google-cloud-bigquery-storage python-dotenv pandas pyarrow tqdm\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aafb654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project_id': 'regal-dynamo-470908-v9', 'dataset_id': 'auckland_data_dev', 'location': 'australia-southeast1', 'route_id': 'INN-202'}\n"
     ]
    }
   ],
   "source": [
    "# Configure variables here\n",
    "project_id = os.environ.get(\"BQ_PROJECT\", \"regal-dynamo-470908-v9\")\n",
    "dataset_id = os.environ.get(\"BQ_DATASET\", \"auckland_data_dev\")\n",
    "location = os.environ.get(\"BQ_LOCATION\", \"australia-southeast1\")\n",
    "# Default route to run (can be changed and rerun)\n",
    "route_id = os.environ.get(\"ROUTE_ID\", \"INN-202\")\n",
    " \n",
    "print({\"project_id\": project_id, \"dataset_id\": dataset_id, \"location\": location, \"route_id\": route_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be004beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery client ready for regal-dynamo-470908-v9 (region set per job: australia-southeast1)\n"
     ]
    }
   ],
   "source": [
    "# Create BigQuery client using ADC or service account JSON if provided\n",
    "credentials_path = os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS_JSON\", None)\n",
    "if credentials_path and Path(credentials_path).exists():\n",
    "    creds = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "    client = bigquery.Client(project=project_id, credentials=creds)\n",
    "else:\n",
    "    client = bigquery.Client(project=project_id)\n",
    "# Note: BigQuery region is provided per query via run_sql_loc(location=...)\n",
    "print(f\"BigQuery client ready for {project_id} (region set per job: {location})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf3725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "def load_sql(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def render_sql(sql: str, params: Dict[str, Any]) -> str:\n",
    "    # Use Template to replace ${var} placeholders present in our SQL files\n",
    "    return Template(sql).substitute(params)\n",
    "\n",
    "def run_sql(sql: str, job_config: bigquery.QueryJobConfig | None = None) -> bigquery.table.RowIterator:\n",
    "    job = client.query(sql, job_config=job_config)\n",
    "    result = job.result()\n",
    "    print(f\"Job {job.job_id} done. bytes={job.total_bytes_processed:,} cached={job.cache_hit}\")\n",
    "    return result\n",
    "\n",
    "def run_sql_loc(sql: str) -> bigquery.table.RowIterator:\n",
    "    # Region-aware query execution (uses the `location` variable)\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job = client.query(sql, job_config=job_config, location=location)\n",
    "    res = job.result()\n",
    "    print(f\"Job {job.job_id} done. location={job.location} bytes={job.total_bytes_processed:,}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13830704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/martin/Projects/mak-group/gcp-example/infrastructure/queries/scheduled/trip_edges_reset.sql\n",
      "/Users/martin/Projects/mak-group/gcp-example/infrastructure/queries/scheduled/trip_edges_insert_by_route.sql\n",
      "/Users/martin/Projects/mak-group/gcp-example/infrastructure/queries/scheduled/route_edges.sql\n"
     ]
    }
   ],
   "source": [
    "# Paths to SQL files\n",
    "root = Path(\"/Users/martin/Projects/mak-group/gcp-example\")\n",
    "sql_dir = root / \"infrastructure\" / \"queries\" / \"scheduled\"\n",
    "trip_edges_reset_path = sql_dir / \"trip_edges_reset.sql\"\n",
    "trip_edges_insert_by_route_path = sql_dir / \"trip_edges_insert_by_route.sql\"\n",
    "route_edges_path = sql_dir / \"route_edges.sql\"\n",
    "print(trip_edges_reset_path)\n",
    "print(trip_edges_insert_by_route_path)\n",
    "print(route_edges_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98ba22cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Reset (recreate empty) trip_edges table with schema and clustering\n",
      "-- Run before shard inserts\n",
      "\n",
      "CREATE OR REPLACE TABLE `regal-dynamo-470908-v9.auckland_data_dev.trip_edges`\n",
      "CLUSTER BY route_id, edge_id AS\n",
      "WITH shapes AS (\n",
      "  SELECT\n",
      "    shape_id,\n",
      "    geom,\n",
      "  ST_BUFFER(geom, 15) AS buf_geom,\n",
      "  ST_BOUNDINGBOX(ST_BUFFER(geom, 15)) AS env_box\n",
      "  FROM `regal-dynamo-470908-v9.auckland_data_dev.shapes_g...\n",
      "\n",
      "Job 465b4578-73f0-4d60-9782-fea36a8ecbcc done. location=australia-southeast1 bytes=0\n",
      "Job 465b4578-73f0-4d60-9782-fea36a8ecbcc done. location=australia-southeast1 bytes=0\n"
     ]
    }
   ],
   "source": [
    "# Reset trip_edges table (empty schema + clustering)\n",
    "params = {\"project_id\": project_id, \"dataset_id\": dataset_id}\n",
    "reset_sql = render_sql(load_sql(str(trip_edges_reset_path)), params)\n",
    "print(reset_sql[:400] + \"...\\n\")\n",
    "_ = run_sql_loc(reset_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee2f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Insert trip_edges for a single route_id shard\n",
      "-- Variables: project_id, dataset_id, route_id\n",
      "\n",
      "INSERT INTO `regal-dynamo-470908-v9.auckland_data_dev.trip_edges`\n",
      "WITH shapes AS (\n",
      "  SELECT\n",
      "    shape_id,\n",
      "    geom,\n",
      "  ST_BUFFER(geom, 15) AS buf_geom,\n",
      "  ST_BOUNDINGBOX(ST_BUFFER(geom, 15)) AS env_box\n",
      "  FROM `regal-dynamo-470908-v9.auckland_data_dev.shapes_geog`\n",
      "), roads AS (\n",
      "  SELECT\n",
      "    edge_id,\n",
      "    n...\n",
      "\n"
     ]
    },
    {
     "ename": "BadRequest",
     "evalue": "400 GET https://bigquery.googleapis.com/bigquery/v2/projects/regal-dynamo-470908-v9/queries/8819baad-39f9-4cb2-a7e8-6e2e65a3a566?maxResults=0&location=australia-southeast1&prettyPrint=false: Query exceeded resource limits. This query used 12326 CPU seconds but would charge only 40M Analysis bytes. This exceeds the ratio supported by the on-demand pricing model. Please consider moving this workload to a capacity-based pricing model, which does not have this limit. 12326 CPU seconds were used, and this query must use less than 10200 CPU seconds.\n\nLocation: australia-southeast1\nJob ID: 8819baad-39f9-4cb2-a7e8-6e2e65a3a566\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequest\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m insert_sql = render_sql(load_sql(\u001b[38;5;28mstr\u001b[39m(trip_edges_insert_by_route_path)), params)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(insert_sql[:\u001b[32m400\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m _ = \u001b[43mrun_sql_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_sql\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mrun_sql_loc\u001b[39m\u001b[34m(sql)\u001b[39m\n\u001b[32m     18\u001b[39m job_config = bigquery.QueryJobConfig()\n\u001b[32m     19\u001b[39m job = client.query(sql, job_config=job_config, location=location)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m res = \u001b[43mjob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJob \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.job_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m done. location=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.location\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m bytes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.total_bytes_processed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/job/query.py:1773\u001b[39m, in \u001b[36mQueryJob.result\u001b[39m\u001b[34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[39m\n\u001b[32m   1768\u001b[39m     remaining_timeout = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1770\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1771\u001b[39m     \u001b[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[39;00m\n\u001b[32m   1772\u001b[39m     \u001b[38;5;66;03m# long-running API, don't delay the next request at all.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_job_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1774\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1776\u001b[39m     \u001b[38;5;66;03m# Use a monotonic clock since we don't actually care about\u001b[39;00m\n\u001b[32m   1777\u001b[39m     \u001b[38;5;66;03m# daylight savings or similar, just the elapsed time.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/job/query.py:1742\u001b[39m, in \u001b[36mQueryJob.result.<locals>.is_job_done\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1736\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;66;03m# Call jobs.getQueryResults with max results set to 0 just to\u001b[39;00m\n\u001b[32m   1739\u001b[39m \u001b[38;5;66;03m# wait for the query to finish. Unlike most methods,\u001b[39;00m\n\u001b[32m   1740\u001b[39m \u001b[38;5;66;03m# jobs.getQueryResults hangs as long as it can to ensure we\u001b[39;00m\n\u001b[32m   1741\u001b[39m \u001b[38;5;66;03m# know when the query has finished as soon as possible.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reload_query_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mreload_query_results_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;66;03m# Even if the query is finished now according to\u001b[39;00m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# jobs.getQueryResults, we'll want to reload the job status if\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# it's not already DONE.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/job/query.py:1534\u001b[39m, in \u001b[36mQueryJob._reload_query_results\u001b[39m\u001b[34m(self, retry, timeout, page_size, start_index)\u001b[39m\n\u001b[32m   1531\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transport_timeout, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)):\n\u001b[32m   1532\u001b[39m         transport_timeout = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1534\u001b[39m \u001b[38;5;28mself\u001b[39m._query_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_query_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1540\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/client.py:2113\u001b[39m, in \u001b[36mClient._get_query_results\u001b[39m\u001b[34m(self, job_id, retry, project, timeout_ms, location, timeout, page_size, start_index)\u001b[39m\n\u001b[32m   2109\u001b[39m \u001b[38;5;66;03m# This call is typically made in a polling loop that checks whether the\u001b[39;00m\n\u001b[32m   2110\u001b[39m \u001b[38;5;66;03m# job is complete (from QueryJob.done(), called ultimately from\u001b[39;00m\n\u001b[32m   2111\u001b[39m \u001b[38;5;66;03m# QueryJob.result()). So we don't need to poll here.\u001b[39;00m\n\u001b[32m   2112\u001b[39m span_attributes = {\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: path}\n\u001b[32m-> \u001b[39m\u001b[32m2113\u001b[39m resource = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBigQuery.getQueryResults\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2121\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _QueryResults.from_api_repr(resource)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/client.py:861\u001b[39m, in \u001b[36mClient._call_api\u001b[39m\u001b[34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[39m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[32m    859\u001b[39m         name=span_name, attributes=span_attributes, client=\u001b[38;5;28mself\u001b[39m, job_ref=job_ref\n\u001b[32m    860\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/_http/__init__.py:494\u001b[39m, in \u001b[36mJSONConnection.api_request\u001b[39m\u001b[34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[39m\n\u001b[32m    482\u001b[39m response = \u001b[38;5;28mself\u001b[39m._make_request(\n\u001b[32m    483\u001b[39m     method=method,\n\u001b[32m    484\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m     extra_api_info=extra_api_info,\n\u001b[32m    491\u001b[39m )\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= response.status_code < \u001b[32m300\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_http_response(response)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response.content:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n",
      "\u001b[31mBadRequest\u001b[39m: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/regal-dynamo-470908-v9/queries/8819baad-39f9-4cb2-a7e8-6e2e65a3a566?maxResults=0&location=australia-southeast1&prettyPrint=false: Query exceeded resource limits. This query used 12326 CPU seconds but would charge only 40M Analysis bytes. This exceeds the ratio supported by the on-demand pricing model. Please consider moving this workload to a capacity-based pricing model, which does not have this limit. 12326 CPU seconds were used, and this query must use less than 10200 CPU seconds.\n\nLocation: australia-southeast1\nJob ID: 8819baad-39f9-4cb2-a7e8-6e2e65a3a566\n"
     ]
    }
   ],
   "source": [
    "# Insert trip_edges for a single route_id\n",
    "params = {\"project_id\": project_id, \"dataset_id\": dataset_id, \"route_id\": route_id}\n",
    "insert_sql = render_sql(load_sql(str(trip_edges_insert_by_route_path)), params)\n",
    "print(insert_sql[:400] + \"...\\n\")\n",
    "_ = run_sql_loc(insert_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build route_edges aggregation from trip_edges\n",
    "params = {\"project_id\": project_id, \"dataset_id\": dataset_id}\n",
    "agg_sql = render_sql(load_sql(str(route_edges_path)), params)\n",
    "print(agg_sql[:300] + \"...\\n\")\n",
    "_ = run_sql_loc(agg_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f26f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: shard mode insert (set shard_mod and run the loop)\n",
    "shard_mod = 4  # increase if any shard is heavy\n",
    "params_base = {\"project_id\": project_id, \"dataset_id\": dataset_id, \"shard_mod\": shard_mod}\n",
    "trip_edges_insert_shard_path = sql_dir / \"trip_edges_insert_shard.sql\"\n",
    "sql_template = load_sql(str(trip_edges_insert_shard_path))\n",
    "for shard in range(shard_mod):\n",
    "    params = {**params_base, \"shard\": shard}\n",
    "    shard_sql = render_sql(sql_template, params)\n",
    "    print(f\"Running shard {shard}/{shard_mod-1}\")\n",
    "    _ = run_sql_loc(shard_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick verification: counts and sample rows\n",
    "verify_sql = f\"\"\"\n",
    "SELECT \n",
    "  (SELECT COUNT(*) FROM `{project_id}.{dataset_id}.trip_edges`) AS trip_edges_rows,\n",
    "  (SELECT COUNT(*) FROM `{project_id}.{dataset_id}.route_edges`) AS route_edges_rows;\n",
    "\"\"\"\n",
    "list_sql = f\"SELECT route_id, COUNT(*) AS edges FROM `{project_id}.{dataset_id}.trip_edges` GROUP BY route_id ORDER BY edges DESC LIMIT 10\"\n",
    "for q in (verify_sql, list_sql):\n",
    "    df = run_sql_loc(q).to_dataframe()\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: materialize shapes_geog if needed\n",
    "shapes_sql_path = sql_dir / \"shapes_geog.sql\"\n",
    "shapes_sql = render_sql(load_sql(str(shapes_sql_path)), {\"project_id\": project_id, \"dataset_id\": dataset_id})\n",
    "print(shapes_sql[:300] + \"...\\n\")\n",
    "_ = run_sql_loc(shapes_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fddead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate BigQuery client with robust credential handling (overrides previous)\n",
    "from google.auth.exceptions import DefaultCredentialsError\n",
    "sa_path = os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\") or os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS_JSON\")\n",
    "creds = None\n",
    "if sa_path:\n",
    "    p = Path(sa_path)\n",
    "    try:\n",
    "        if p.exists():\n",
    "            creds = service_account.Credentials.from_service_account_file(str(p))\n",
    "        else:\n",
    "            # Try treating env as JSON content\n",
    "            try:\n",
    "                info = json.loads(sa_path)\n",
    "                creds = service_account.Credentials.from_service_account_info(info)\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        print(f\"Service account credential parse failed: {e}\")\n",
    "try:\n",
    "    if creds is not None:\n",
    "        client = bigquery.Client(project=project_id, credentials=creds)\n",
    "    else:\n",
    "        client = bigquery.Client(project=project_id)\n",
    "    print(f\"BigQuery client ready for {project_id} (region set per job: {location})\")\n",
    "except DefaultCredentialsError as e:\n",
    "    raise RuntimeError(\"No GCP credentials found. Use gcloud auth application-default login or set GOOGLE_APPLICATION_CREDENTIALS.\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d68a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to run a query in a specific location\n",
    "def run_sql_loc(sql: str) -> bigquery.table.RowIterator:\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job = client.query(sql, job_config=job_config, location=location)\n",
    "    res = job.result()\n",
    "    print(f\"Job {job.job_id} done. location={job.location} bytes={job.total_bytes_processed:,}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d53f3d1",
   "metadata": {},
   "source": [
    "## Fallback: chunked insert by shape_id\n",
    "If the single-route insert exceeds on-demand CPU ratio, run the route in smaller chunks by shape_id. This adds a WHERE shape_id IN (...) to each chunk and repeats until all shapes are processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94f29ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: fetch shape_ids for a route and run chunked inserts\n",
    "\n",
    "def fetch_shape_ids_for_route(route_id: str) -> list[str]:\n",
    "    q = f\"\"\"\n",
    "    SELECT DISTINCT shape_id\n",
    "    FROM `{project_id}.{dataset_id}.sc_trips`\n",
    "    WHERE route_id = @route_id\n",
    "    ORDER BY shape_id\n",
    "    \"\"\"\n",
    "    job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter(\"route_id\", \"STRING\", route_id)])\n",
    "    rows = client.query(q, job_config=job_config, location=location).result()\n",
    "    return [r[0] for r in rows]\n",
    "\n",
    "\n",
    "def render_insert_with_shape_filter(base_sql: str, shape_ids: list[str], route_id: str) -> str:\n",
    "    # Safely append an AND shape_id IN (...) predicate to the trips CTE WHERE route_id = \"...\"\n",
    "    in_list = \", \".join([\"'\" + s + \"'\" for s in shape_ids])\n",
    "    pattern = f'WHERE route_id = \"{route_id}\"'\n",
    "    if pattern in base_sql:\n",
    "        return base_sql.replace(pattern, pattern + f\"\\n  AND shape_id IN ({in_list})\", 1)\n",
    "    alt_pattern = f\"WHERE route_id = '{route_id}'\"\n",
    "    if alt_pattern in base_sql:\n",
    "        return base_sql.replace(alt_pattern, alt_pattern + f\"\\n  AND shape_id IN ({in_list})\", 1)\n",
    "    # Fallback: inject just before the end of the trips CTE\n",
    "    return base_sql.replace(\"\\n)\\nSELECT\", f\"\\n  AND shape_id IN ({in_list})\\n)\\nSELECT\", 1)\n",
    "\n",
    "\n",
    "def ensure_antijoin_once(sql: str, project_id: str, dataset_id: str) -> str:\n",
    "    # If the base SQL already includes an anti-join, skip; else inject it\n",
    "    te_phrase = f\"LEFT JOIN `{project_id}.{dataset_id}.trip_edges` te\"\n",
    "    if te_phrase in sql or \" te.trip_id IS NULL\" in sql:\n",
    "        return sql\n",
    "    te = f\"`{project_id}.{dataset_id}.trip_edges`\"\n",
    "    join_clause = f\"\\nLEFT JOIN {te} te ON te.trip_id = t.trip_id AND te.edge_id = r.edge_id\\nWHERE te.trip_id IS NULL AND \"\n",
    "    return sql.replace(\"\\nWHERE \", join_clause, 1)\n",
    "\n",
    "\n",
    "def render_insert_with_shape_filter_and_antijoin(base_sql: str, shape_ids: list[str], route_id: str, project_id: str, dataset_id: str) -> str:\n",
    "    sql = render_insert_with_shape_filter(base_sql, shape_ids, route_id)\n",
    "    return ensure_antijoin_once(sql, project_id, dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3898558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route INN-202 has 16 distinct shape_ids\n",
      "Inserting chunk 1 with 1 shape(s): ['1286-79821-0d6c86f9']\n",
      "Job fc4ad879-43b7-48fd-9eec-d16b42fc0b8a done. location=australia-southeast1 bytes=37,636,178\n",
      "Inserting chunk 2 with 1 shape(s): ['1286-79821-2928d84f']\n",
      "Job fc4ad879-43b7-48fd-9eec-d16b42fc0b8a done. location=australia-southeast1 bytes=37,636,178\n",
      "Inserting chunk 2 with 1 shape(s): ['1286-79821-2928d84f']\n",
      "Job 9c362942-389a-4b36-a15d-fb1c056c53b8 done. location=australia-southeast1 bytes=39,924,443\n",
      "Inserting chunk 3 with 1 shape(s): ['1286-79823-209afed3']\n",
      "Job 9c362942-389a-4b36-a15d-fb1c056c53b8 done. location=australia-southeast1 bytes=39,924,443\n",
      "Inserting chunk 3 with 1 shape(s): ['1286-79823-209afed3']\n",
      "Job cbb7d21c-62bb-461a-a844-90a63a632f26 done. location=australia-southeast1 bytes=42,212,708\n",
      "Inserting chunk 4 with 1 shape(s): ['1286-79823-4d73cc7f']\n",
      "Job cbb7d21c-62bb-461a-a844-90a63a632f26 done. location=australia-southeast1 bytes=42,212,708\n",
      "Inserting chunk 4 with 1 shape(s): ['1286-79823-4d73cc7f']\n",
      "Job 72af1c76-5ee3-487c-a42b-7e14c7191224 done. location=australia-southeast1 bytes=42,252,668\n",
      "Inserting chunk 5 with 1 shape(s): ['1286-79825-0d468b1b']\n",
      "Job 72af1c76-5ee3-487c-a42b-7e14c7191224 done. location=australia-southeast1 bytes=42,252,668\n",
      "Inserting chunk 5 with 1 shape(s): ['1286-79825-0d468b1b']\n",
      "Job 44744560-da99-42ad-9591-99a24bf73c38 done. location=australia-southeast1 bytes=42,292,628\n",
      "Inserting chunk 6 with 1 shape(s): ['1286-79825-1c3356f6']\n",
      "Job 44744560-da99-42ad-9591-99a24bf73c38 done. location=australia-southeast1 bytes=42,292,628\n",
      "Inserting chunk 6 with 1 shape(s): ['1286-79825-1c3356f6']\n",
      "Job 8ac9b605-59a2-45af-bd8b-656920c6a97d done. location=australia-southeast1 bytes=42,325,928\n",
      "Inserting chunk 7 with 1 shape(s): ['1286-79831-0d6c86f9']\n",
      "Job 8ac9b605-59a2-45af-bd8b-656920c6a97d done. location=australia-southeast1 bytes=42,325,928\n",
      "Inserting chunk 7 with 1 shape(s): ['1286-79831-0d6c86f9']\n",
      "Job dde0c273-8b8c-479e-b31e-5dff379a0129 done. location=australia-southeast1 bytes=42,359,228\n",
      "Inserting chunk 8 with 1 shape(s): ['1286-79831-2928d84f']\n",
      "Job dde0c273-8b8c-479e-b31e-5dff379a0129 done. location=australia-southeast1 bytes=42,359,228\n",
      "Inserting chunk 8 with 1 shape(s): ['1286-79831-2928d84f']\n",
      "Job 7f43fd5d-5f5b-4f7a-b6ad-7aac4505b55c done. location=australia-southeast1 bytes=42,415,431\n",
      "Inserting chunk 9 with 1 shape(s): ['1286-79922-64308da8']\n",
      "Job 7f43fd5d-5f5b-4f7a-b6ad-7aac4505b55c done. location=australia-southeast1 bytes=42,415,431\n",
      "Inserting chunk 9 with 1 shape(s): ['1286-79922-64308da8']\n",
      "Job 1472c946-d433-42b3-b7f1-e5b16c0d3250 done. location=australia-southeast1 bytes=42,471,634\n",
      "Inserting chunk 10 with 1 shape(s): ['1286-79922-c1a013be']\n",
      "Job 1472c946-d433-42b3-b7f1-e5b16c0d3250 done. location=australia-southeast1 bytes=42,471,634\n",
      "Inserting chunk 10 with 1 shape(s): ['1286-79922-c1a013be']\n",
      "Job ff76eeb5-1ec9-4ee4-b4ae-25eec40501c7 done. location=australia-southeast1 bytes=44,956,480\n",
      "Inserting chunk 11 with 1 shape(s): ['1286-79924-11ab22e6']\n",
      "Job ff76eeb5-1ec9-4ee4-b4ae-25eec40501c7 done. location=australia-southeast1 bytes=44,956,480\n",
      "Inserting chunk 11 with 1 shape(s): ['1286-79924-11ab22e6']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m chunk_sql = render_insert_with_shape_filter_and_antijoin(base_sql, batch, route_id, project_id, dataset_id)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInserting chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi//chunk_size\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m shape(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m _ = \u001b[43mrun_sql_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_sql\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mrun_sql_loc\u001b[39m\u001b[34m(sql)\u001b[39m\n\u001b[32m     18\u001b[39m job_config = bigquery.QueryJobConfig()\n\u001b[32m     19\u001b[39m job = client.query(sql, job_config=job_config, location=location)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m res = \u001b[43mjob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJob \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.job_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m done. location=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.location\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m bytes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.total_bytes_processed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/job/query.py:1773\u001b[39m, in \u001b[36mQueryJob.result\u001b[39m\u001b[34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[39m\n\u001b[32m   1768\u001b[39m     remaining_timeout = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1770\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1771\u001b[39m     \u001b[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[39;00m\n\u001b[32m   1772\u001b[39m     \u001b[38;5;66;03m# long-running API, don't delay the next request at all.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_job_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1774\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1776\u001b[39m     \u001b[38;5;66;03m# Use a monotonic clock since we don't actually care about\u001b[39;00m\n\u001b[32m   1777\u001b[39m     \u001b[38;5;66;03m# daylight savings or similar, just the elapsed time.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/job/query.py:1742\u001b[39m, in \u001b[36mQueryJob.result.<locals>.is_job_done\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1736\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;66;03m# Call jobs.getQueryResults with max results set to 0 just to\u001b[39;00m\n\u001b[32m   1739\u001b[39m \u001b[38;5;66;03m# wait for the query to finish. Unlike most methods,\u001b[39;00m\n\u001b[32m   1740\u001b[39m \u001b[38;5;66;03m# jobs.getQueryResults hangs as long as it can to ensure we\u001b[39;00m\n\u001b[32m   1741\u001b[39m \u001b[38;5;66;03m# know when the query has finished as soon as possible.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1742\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reload_query_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mreload_query_results_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;66;03m# Even if the query is finished now according to\u001b[39;00m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# jobs.getQueryResults, we'll want to reload the job status if\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# it's not already DONE.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/job/query.py:1534\u001b[39m, in \u001b[36mQueryJob._reload_query_results\u001b[39m\u001b[34m(self, retry, timeout, page_size, start_index)\u001b[39m\n\u001b[32m   1531\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transport_timeout, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)):\n\u001b[32m   1532\u001b[39m         transport_timeout = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1534\u001b[39m \u001b[38;5;28mself\u001b[39m._query_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_query_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1540\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/client.py:2113\u001b[39m, in \u001b[36mClient._get_query_results\u001b[39m\u001b[34m(self, job_id, retry, project, timeout_ms, location, timeout, page_size, start_index)\u001b[39m\n\u001b[32m   2109\u001b[39m \u001b[38;5;66;03m# This call is typically made in a polling loop that checks whether the\u001b[39;00m\n\u001b[32m   2110\u001b[39m \u001b[38;5;66;03m# job is complete (from QueryJob.done(), called ultimately from\u001b[39;00m\n\u001b[32m   2111\u001b[39m \u001b[38;5;66;03m# QueryJob.result()). So we don't need to poll here.\u001b[39;00m\n\u001b[32m   2112\u001b[39m span_attributes = {\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: path}\n\u001b[32m-> \u001b[39m\u001b[32m2113\u001b[39m resource = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBigQuery.getQueryResults\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2121\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _QueryResults.from_api_repr(resource)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/client.py:861\u001b[39m, in \u001b[36mClient._call_api\u001b[39m\u001b[34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[39m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[32m    859\u001b[39m         name=span_name, attributes=span_attributes, client=\u001b[38;5;28mself\u001b[39m, job_ref=job_ref\n\u001b[32m    860\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/_http/__init__.py:482\u001b[39m, in \u001b[36mJSONConnection.api_request\u001b[39m\u001b[34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[39m\n\u001b[32m    479\u001b[39m     data = json.dumps(data)\n\u001b[32m    480\u001b[39m     content_type = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_object\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_target_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_api_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_api_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= response.status_code < \u001b[32m300\u001b[39m:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_http_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/_http/__init__.py:341\u001b[39m, in \u001b[36mJSONConnection._make_request\u001b[39m\u001b[34m(self, method, url, data, content_type, headers, target_object, timeout, extra_api_info)\u001b[39m\n\u001b[32m    338\u001b[39m     headers[CLIENT_INFO_HEADER] = \u001b[38;5;28mself\u001b[39m.user_agent\n\u001b[32m    339\u001b[39m headers[\u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.user_agent\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/_http/__init__.py:379\u001b[39m, in \u001b[36mJSONConnection._do_request\u001b[39m\u001b[34m(self, method, url, headers, data, target_object, timeout)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_do_request\u001b[39m(\n\u001b[32m    346\u001b[39m     \u001b[38;5;28mself\u001b[39m, method, url, headers, data, target_object, timeout=_DEFAULT_TIMEOUT\n\u001b[32m    347\u001b[39m ):  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[32m    348\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Low-level helper:  perform the actual API request over HTTP.\u001b[39;00m\n\u001b[32m    349\u001b[39m \n\u001b[32m    350\u001b[39m \u001b[33;03m    Allows batch context managers to override and defer a request.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    377\u001b[39m \u001b[33;03m    :returns: The HTTP response.\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/auth/transport/requests.py:540\u001b[39m, in \u001b[36mAuthorizedSession.request\u001b[39m\u001b[34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m TimeoutGuard(remaining_time) \u001b[38;5;28;01mas\u001b[39;00m guard:\n\u001b[32m    539\u001b[39m     _helpers.request_log(_LOGGER, method, url, data, headers)\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m     response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAuthorizedSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    548\u001b[39m remaining_time = guard.remaining_timeout\n\u001b[32m    550\u001b[39m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[32m    552\u001b[39m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[32m    553\u001b[39m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[32m    554\u001b[39m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.11/3.11.12/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run chunked insert for the current route_id\n",
    "one_shape_at_a_time = True  # set True to process 1 shape_id per query\n",
    "chunk_size = 1 if one_shape_at_a_time else 10  # adjust smaller if still hitting CPU ratio\n",
    "all_shapes = fetch_shape_ids_for_route(route_id)\n",
    "print(f\"Route {route_id} has {len(all_shapes)} distinct shape_ids\")\n",
    "params = {\"project_id\": project_id, \"dataset_id\": dataset_id, \"route_id\": route_id}\n",
    "base_sql = render_sql(load_sql(str(trip_edges_insert_by_route_path)), params)\n",
    "for i in range(0, len(all_shapes), chunk_size):\n",
    "    batch = all_shapes[i:i+chunk_size]\n",
    "    chunk_sql = render_insert_with_shape_filter_and_antijoin(base_sql, batch, route_id, project_id, dataset_id)\n",
    "    print(f\"Inserting chunk {i//chunk_size + 1} with {len(batch)} shape(s): {batch}\")\n",
    "    _ = run_sql_loc(chunk_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb587d6",
   "metadata": {},
   "source": [
    "## Diagnostics: sanity-check trip_edges volume\n",
    "Let’s check whether the high row count is expected:\n",
    "- Total trip_edges rows vs distinct (trip_id, edge_id) pairs (duplicate check)\n",
    "- Number of trips for this route\n",
    "- Edges-per-trip stats (avg/min/max)\n",
    "- If available, edges-per-shape from `shape_edges` for this route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnose shape_edges volume for current route under different thresholds\n",
    "params = [bigquery.ScalarQueryParameter(\"route_id\", \"STRING\", route_id)]\n",
    "diag_sql = f\"\"\"\n",
    "WITH r_shapes AS (\n",
    "  SELECT DISTINCT shape_id FROM `{project_id}.{dataset_id}.sc_trips` WHERE route_id = @route_id\n",
    "), counts AS (\n",
    "  SELECT\n",
    "    'current' AS variant, COUNT(*) AS rows\n",
    "  FROM `{project_id}.{dataset_id}.shape_edges`\n",
    "  WHERE shape_id IN (SELECT shape_id FROM r_shapes)\n",
    "), alt AS (\n",
    "  SELECT\n",
    "    'alt_strict' AS variant, COUNT(*) AS rows\n",
    "  FROM (\n",
    "    WITH s AS (\n",
    "      SELECT shape_id, geom, ST_BUFFER(geom, 6) AS buf_geom\n",
    "      FROM `{project_id}.{dataset_id}.shapes_geog`\n",
    "      WHERE shape_id IN (SELECT shape_id FROM r_shapes)\n",
    "    ), r AS (\n",
    "      SELECT edge_id, highway, length_m AS edge_length_m, ST_SIMPLIFY(geom, 7) AS simple_geom\n",
    "      FROM `{project_id}.{dataset_id}.vw_osm_akl_road_links`\n",
    "      WHERE highway NOT IN ('footway','path','cycleway','steps','track','pedestrian','bridleway','corridor')\n",
    "    )\n",
    "    SELECT s.shape_id, r.edge_id,\n",
    "           ST_LENGTH(ST_INTERSECTION(r.simple_geom, s.buf_geom)) AS overlap_m, r.edge_length_m\n",
    "    FROM s JOIN r\n",
    "    ON ST_DWithin(r.simple_geom, s.buf_geom, 0)\n",
    "  )\n",
    "  WHERE overlap_m > 40 AND overlap_m / edge_length_m >= 0.15\n",
    ")\n",
    "SELECT * FROM counts\n",
    "UNION ALL\n",
    "SELECT * FROM alt\n",
    "\"\"\"\n",
    "job = client.query(diag_sql, job_config=bigquery.QueryJobConfig(query_parameters=params), location=location)\n",
    "df = job.result().to_dataframe()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics queries for the current route_id\n",
    "from IPython.display import display\n",
    "\n",
    "q_overview = f\"\"\"\n",
    "WITH te AS (\n",
    "  SELECT * FROM `{project_id}.{dataset_id}.trip_edges` WHERE route_id = @route_id\n",
    ")\n",
    "SELECT\n",
    "  (SELECT COUNT(*) FROM te) AS total_rows,\n",
    "  (SELECT COUNT(*) FROM (SELECT DISTINCT trip_id, edge_id FROM te)) AS distinct_trip_edge_pairs,\n",
    "  (SELECT COUNT(DISTINCT trip_id) FROM te) AS trips,\n",
    "  SAFE_DIVIDE((SELECT COUNT(*) FROM te), (SELECT COUNT(DISTINCT trip_id) FROM te)) AS avg_edges_per_trip\n",
    "\"\"\"\n",
    "\n",
    "q_edges_per_trip_stats = f\"\"\"\n",
    "SELECT\n",
    "  APPROX_QUANTILES(cnt, 10) AS deciles,\n",
    "  MIN(cnt) AS min_edges,\n",
    "  AVG(cnt) AS avg_edges,\n",
    "  MAX(cnt) AS max_edges\n",
    "FROM (\n",
    "  SELECT trip_id, COUNT(*) AS cnt\n",
    "  FROM `{project_id}.{dataset_id}.trip_edges`\n",
    "  WHERE route_id = @route_id\n",
    "  GROUP BY trip_id\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "q_shape_edges_stats = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS shape_edge_rows,\n",
    "  COUNT(DISTINCT shape_id) AS shapes,\n",
    "  SAFE_DIVIDE(COUNT(*), COUNT(DISTINCT shape_id)) AS avg_edges_per_shape\n",
    "FROM `{project_id}.{dataset_id}.shape_edges`\n",
    "WHERE shape_id IN (\n",
    "  SELECT DISTINCT shape_id FROM `{project_id}.{dataset_id}.sc_trips` WHERE route_id = @route_id\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "params = [bigquery.ScalarQueryParameter(\"route_id\", \"STRING\", route_id)]\n",
    "for label, q in [\n",
    "    (\"trip_edges overview\", q_overview),\n",
    "    (\"edges per trip stats\", q_edges_per_trip_stats),\n",
    "    (\"shape_edges stats (if table exists)\", q_shape_edges_stats),\n",
    "]:\n",
    "    try:\n",
    "        job = client.query(q, job_config=bigquery.QueryJobConfig(query_parameters=params), location=location)\n",
    "        df = job.result().to_dataframe()\n",
    "        print(label)\n",
    "        display(df)\n",
    "    except Exception as e:\n",
    "        print(f\"{label} failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b9906",
   "metadata": {},
   "source": [
    "## Alternative path: materialize shape_edges then expand to trip_edges\n",
    "This avoids recomputing spatial intersections per trip when many trips share the same shape_id. Steps:\n",
    "1) Build `shape_edges` once\n",
    "2) Insert `trip_edges` for a route from `shape_edges` (fast expansion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63170a",
   "metadata": {},
   "source": [
    "## Incremental builder: shape_edges one shape at a time\n",
    "Use this when you hit CPU limits or want to resume partially. It inserts shape→edge links for each shape_id with an anti-join to skip already-processed pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf8499bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 8728a49a-8b76-4903-bbf6-a4ed641a13f6 done. location=australia-southeast1 bytes=0\n",
      "Route INN-202 has 16 shape_ids to process\n",
      "[1/16] Inserting shape_edges for shape_id=1286-79821-0d6c86f9\n",
      "Route INN-202 has 16 shape_ids to process\n",
      "[1/16] Inserting shape_edges for shape_id=1286-79821-0d6c86f9\n"
     ]
    },
    {
     "ename": "BadRequest",
     "evalue": "400 No matching signature for operator = for argument types: STRING, INT64\n  Signature: T1 = T1\n    Unable to find common supertype for templated argument <T1>\n      Input types for <T1>: {INT64, STRING} at [41:35]; reason: invalidQuery, location: query, message: No matching signature for operator = for argument types: STRING, INT64\n  Signature: T1 = T1\n    Unable to find common supertype for templated argument <T1>\n      Input types for <T1>: {INT64, STRING} at [41:35]\n\nLocation: australia-southeast1\nJob ID: 396ee8b2-3610-4763-a7f3-7c3f8a00627f\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequest\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m     sql = render_sql(load_sql(\u001b[38;5;28mstr\u001b[39m(shape_edges_by_shape_path)), {\u001b[33m\"\u001b[39m\u001b[33mproject_id\u001b[39m\u001b[33m\"\u001b[39m: project_id, \u001b[33m\"\u001b[39m\u001b[33mdataset_id\u001b[39m\u001b[33m\"\u001b[39m: dataset_id, \u001b[33m\"\u001b[39m\u001b[33mshape_id\u001b[39m\u001b[33m\"\u001b[39m: sid})\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(route_shapes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Inserting shape_edges for shape_id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msid\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     _ = \u001b[43mrun_sql_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone building shape_edges incrementally for route\u001b[39m\u001b[33m\"\u001b[39m, route_id)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mrun_sql_loc\u001b[39m\u001b[34m(sql)\u001b[39m\n\u001b[32m     18\u001b[39m job_config = bigquery.QueryJobConfig()\n\u001b[32m     19\u001b[39m job = client.query(sql, job_config=job_config, location=location)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m res = \u001b[43mjob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJob \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.job_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m done. location=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.location\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m bytes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.total_bytes_processed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/job/query.py:1773\u001b[39m, in \u001b[36mQueryJob.result\u001b[39m\u001b[34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[39m\n\u001b[32m   1768\u001b[39m     remaining_timeout = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1770\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1771\u001b[39m     \u001b[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[39;00m\n\u001b[32m   1772\u001b[39m     \u001b[38;5;66;03m# long-running API, don't delay the next request at all.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_job_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1774\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1776\u001b[39m     \u001b[38;5;66;03m# Use a monotonic clock since we don't actually care about\u001b[39;00m\n\u001b[32m   1777\u001b[39m     \u001b[38;5;66;03m# daylight savings or similar, just the elapsed time.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mak-group/gcp-example/notebooks/.venv/lib/python3.11/site-packages/google/cloud/bigquery/job/query.py:1722\u001b[39m, in \u001b[36mQueryJob.result.<locals>.is_job_done\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m job_failed_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1700\u001b[39m     \u001b[38;5;66;03m# Only try to restart the query job if the job failed for\u001b[39;00m\n\u001b[32m   1701\u001b[39m     \u001b[38;5;66;03m# a retriable reason. For example, don't restart the query\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1719\u001b[39m     \u001b[38;5;66;03m# into an exception that can be processed by the\u001b[39;00m\n\u001b[32m   1720\u001b[39m     \u001b[38;5;66;03m# `job_retry` predicate.\u001b[39;00m\n\u001b[32m   1721\u001b[39m     restart_query_job = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1722\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m job_failed_exception\n\u001b[32m   1723\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1724\u001b[39m     \u001b[38;5;66;03m# Make sure that the _query_results are cached so we\u001b[39;00m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;66;03m# can return a complete RowIterator.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1731\u001b[39m     \u001b[38;5;66;03m# making any extra API calls if the previous loop\u001b[39;00m\n\u001b[32m   1732\u001b[39m     \u001b[38;5;66;03m# iteration fetched the finished job.\u001b[39;00m\n\u001b[32m   1733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reload_query_results(\n\u001b[32m   1734\u001b[39m         retry=retry, **reload_query_results_kwargs\n\u001b[32m   1735\u001b[39m     )\n",
      "\u001b[31mBadRequest\u001b[39m: 400 No matching signature for operator = for argument types: STRING, INT64\n  Signature: T1 = T1\n    Unable to find common supertype for templated argument <T1>\n      Input types for <T1>: {INT64, STRING} at [41:35]; reason: invalidQuery, location: query, message: No matching signature for operator = for argument types: STRING, INT64\n  Signature: T1 = T1\n    Unable to find common supertype for templated argument <T1>\n      Input types for <T1>: {INT64, STRING} at [41:35]\n\nLocation: australia-southeast1\nJob ID: 396ee8b2-3610-4763-a7f3-7c3f8a00627f\n"
     ]
    }
   ],
   "source": [
    "# Build shape_edges incrementally, one shape at a time (filtered by current route)\n",
    "shape_edges_by_shape_path = sql_dir / \"shape_edges_insert_by_shape.sql\"\n",
    "\n",
    "# Ensure the base table exists (empty create if missing)\n",
    "create_if_missing = f\"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS `{project_id}.{dataset_id}`;\n",
    "CREATE TABLE IF NOT EXISTS `{project_id}.{dataset_id}.shape_edges` (\n",
    "  shape_id STRING,\n",
    "  edge_id STRING,\n",
    "  road_name STRING,\n",
    "  highway STRING,\n",
    "  oneway STRING,\n",
    "  maxspeed STRING,\n",
    "  edge_length_m FLOAT64,\n",
    "  overlap_m FLOAT64,\n",
    "  edge_geom GEOGRAPHY\n",
    ") CLUSTER BY shape_id, edge_id;\n",
    "\"\"\"\n",
    "_ = run_sql_loc(create_if_missing)\n",
    "\n",
    "# Fetch shapes for the current route\n",
    "route_shapes = fetch_shape_ids_for_route(route_id)\n",
    "print(f\"Route {route_id} has {len(route_shapes)} shape_ids to process\")\n",
    "\n",
    "# Process one shape per query; you can adjust to batches if desired\n",
    "for idx, sid in enumerate(route_shapes, start=1):\n",
    "    sql = render_sql(load_sql(str(shape_edges_by_shape_path)), {\"project_id\": project_id, \"dataset_id\": dataset_id, \"shape_id\": sid})\n",
    "    print(f\"[{idx}/{len(route_shapes)}] Inserting shape_edges for shape_id={sid}\")\n",
    "    _ = run_sql_loc(sql)\n",
    "\n",
    "print(\"Done building shape_edges incrementally for route\", route_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run alternative path: shape_edges -> trip_edges (by route)\n",
    "shape_edges_path = sql_dir / \"shape_edges.sql\"\n",
    "trip_edges_from_shapes_path = sql_dir / \"trip_edges_insert_by_route_from_shapes.sql\"\n",
    "print(shape_edges_path)\n",
    "print(trip_edges_from_shapes_path)\n",
    "shape_edges_sql = render_sql(load_sql(str(shape_edges_path)), {\"project_id\": project_id, \"dataset_id\": dataset_id})\n",
    "_ = run_sql_loc(shape_edges_sql)\n",
    "trip_from_shapes_sql = render_sql(load_sql(str(trip_edges_from_shapes_path)), {\"project_id\": project_id, \"dataset_id\": dataset_id, \"route_id\": route_id})\n",
    "_ = run_sql_loc(trip_from_shapes_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b782e26",
   "metadata": {},
   "source": [
    "## Speed-ups and options\n",
    "- Prefer the shape_edges -> trip_edges alternative path (compute spatial joins once per shape).\n",
    "- Run shapes in parallel (careful with quotas): 2–4 workers is a safe start.\n",
    "- Reduce geometry costs: smaller buffer (e.g., 10m), coarser simplify (e.g., 7–10), higher overlap threshold (e.g., 30–50m).\n",
    "- Use smaller batches if you see CPU ratio errors; anti-join prevents duplicates on reruns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: run shape chunks in parallel (advanced)\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "max_workers = 3  # start with 2-4; increase cautiously\n",
    "one_shape_at_a_time = True\n",
    "chunk_size = 1 if one_shape_at_a_time else 5\n",
    "all_shapes = fetch_shape_ids_for_route(route_id)\n",
    "params = {\"project_id\": project_id, \"dataset_id\": dataset_id, \"route_id\": route_id}\n",
    "base_sql = render_sql(load_sql(str(trip_edges_insert_by_route_path)), params)\n",
    "\n",
    "def exec_batch(batch: list[str]) -> tuple[int, int]:\n",
    "    sql = render_insert_with_shape_filter_and_antijoin(base_sql, batch, route_id, project_id, dataset_id)\n",
    "    run_sql_loc(sql)\n",
    "    return (len(batch), 1)\n",
    "\n",
    "batches = [all_shapes[i:i+chunk_size] for i in range(0, len(all_shapes), chunk_size)]\n",
    "submitted = 0\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "    futures = {ex.submit(exec_batch, b): b for b in batches}\n",
    "    for fut in as_completed(futures):\n",
    "        batch = futures[fut]\n",
    "        try:\n",
    "            cnt, _ = fut.result()\n",
    "            print(f\"Done batch of {cnt} shapes: {batch}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Batch failed for {batch}: {e}\")\n",
    "        submitted += 1\n",
    "print(f\"Completed {submitted}/{len(batches)} batches\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
