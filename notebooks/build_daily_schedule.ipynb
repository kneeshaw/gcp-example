{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ffd6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the src directory to Python path so we can import from src modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import existing BigQuery utilities\n",
    "from bigquery.bigquery_client import _bq_client\n",
    "from common.logging_utils import logger\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d9c2f",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "711c3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your GCP project and dataset\n",
    "PROJECT_ID = \"regal-dynamo-470908-v9\"\n",
    "DATASET = \"auckland_data_dev\"\n",
    "SERVICE_DATE = 20250914  # 14 September 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9afc614",
   "metadata": {},
   "source": [
    "# Step 1: Get Feed Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "751cf203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Feed hash: 9c9a42de469af40e4367e411c387577a\n"
     ]
    }
   ],
   "source": [
    "client = _bq_client(PROJECT_ID)\n",
    "query = f\"\"\"\n",
    "SELECT feed_hash FROM `{PROJECT_ID}.{DATASET}.sc_feed_info` \n",
    "WHERE feed_start_date <= {SERVICE_DATE} \n",
    "AND feed_end_date >= {SERVICE_DATE} \n",
    "ORDER BY ingestion_timestamp DESC LIMIT 1\n",
    "\"\"\"\n",
    "feed_df = client.query(query).to_dataframe()\n",
    "\n",
    "if not feed_df.empty:\n",
    "    APPLICABLE_FEED_HASH = feed_df.iloc[0]['feed_hash']\n",
    "    logger.info(f\"Feed hash: {APPLICABLE_FEED_HASH}\")\n",
    "else:\n",
    "    APPLICABLE_FEED_HASH = None\n",
    "    logger.info(\"No feed found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d059677",
   "metadata": {},
   "source": [
    "# Step 2: Get Active Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e4fa73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Active services: 16\n"
     ]
    }
   ],
   "source": [
    "if APPLICABLE_FEED_HASH:\n",
    "    from datetime import date\n",
    "    date_obj = date(SERVICE_DATE // 10000, (SERVICE_DATE % 10000) // 100, SERVICE_DATE % 100)\n",
    "    day_name = date_obj.strftime('%A').lower()\n",
    "\n",
    "    # Get regular services\n",
    "    calendar_query = f\"\"\"\n",
    "    SELECT service_id FROM `{PROJECT_ID}.{DATASET}.sc_calendar`\n",
    "    WHERE feed_hash = '{APPLICABLE_FEED_HASH}'\n",
    "    AND start_date <= {SERVICE_DATE} AND end_date >= {SERVICE_DATE}\n",
    "    AND {day_name} = 1\n",
    "    \"\"\"\n",
    "    calendar_df = client.query(calendar_query).to_dataframe()\n",
    "    regular_services = set(calendar_df['service_id'].tolist())\n",
    "\n",
    "    # Get added services (exception_type = 1)\n",
    "    added_query = f\"\"\"\n",
    "    SELECT service_id FROM `{PROJECT_ID}.{DATASET}.sc_calendar_dates`\n",
    "    WHERE feed_hash = '{APPLICABLE_FEED_HASH}'\n",
    "    AND date = {SERVICE_DATE} AND exception_type = 1\n",
    "    \"\"\"\n",
    "    added_df = client.query(added_query).to_dataframe()\n",
    "    added_services = set(added_df['service_id'].tolist())\n",
    "\n",
    "    # Get removed services (exception_type = 2)\n",
    "    removed_query = f\"\"\"\n",
    "    SELECT service_id FROM `{PROJECT_ID}.{DATASET}.sc_calendar_dates`\n",
    "    WHERE feed_hash = '{APPLICABLE_FEED_HASH}'\n",
    "    AND date = {SERVICE_DATE} AND exception_type = 2\n",
    "    \"\"\"\n",
    "    removed_df = client.query(removed_query).to_dataframe()\n",
    "    removed_services = set(removed_df['service_id'].tolist())\n",
    "\n",
    "    # Combine: (regular + added) - removed\n",
    "    active_services = (regular_services | added_services) - removed_services\n",
    "    active_services = list(active_services)\n",
    "    logger.info(f\"Active service ids: {len(active_services)}\")\n",
    "else:\n",
    "    active_services = []\n",
    "    logger.info(\"No feed hash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555649f",
   "metadata": {},
   "source": [
    "# Step 3: Get Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d16772b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - All trips: 29302\n",
      "INFO - Filtered trips: 10493\n",
      "INFO - Filtered trips: 10493\n"
     ]
    }
   ],
   "source": [
    "if APPLICABLE_FEED_HASH:\n",
    "    # Get ALL trips for this feed (no filtering in SQL)\n",
    "    trips_query = f\"\"\"\n",
    "    SELECT\n",
    "        t.service_id, t.route_id, r.route_short_name, r.route_type,\n",
    "        t.trip_id, t.trip_headsign, t.direction_id, t.shape_id\n",
    "    FROM `{PROJECT_ID}.{DATASET}.sc_trips` t\n",
    "    LEFT JOIN `{PROJECT_ID}.{DATASET}.sc_routes` r\n",
    "    ON t.route_id = r.route_id AND t.feed_hash = r.feed_hash\n",
    "    WHERE t.feed_hash = '{APPLICABLE_FEED_HASH}'\n",
    "    \"\"\"\n",
    "    all_trips_df = client.query(trips_query).to_dataframe()\n",
    "\n",
    "    # Filter by active services in pandas\n",
    "    if active_services:\n",
    "        trips_df = all_trips_df[all_trips_df['service_id'].isin(active_services)]\n",
    "    else:\n",
    "        trips_df = pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"All trips: {len(all_trips_df)}\")\n",
    "    logger.info(f\"Filtered trips: {len(trips_df)}\")\n",
    "else:\n",
    "    trips_df = pd.DataFrame()\n",
    "    logger.info(\"No feed hash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a513d",
   "metadata": {},
   "source": [
    "# Step 4: Get Stop Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2eb215a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Stop times: 870102\n",
      "INFO - Schedule entries: 315112\n",
      "INFO - Schedule entries: 315112\n"
     ]
    }
   ],
   "source": [
    "def convert_gtfs_time_to_utc(service_date, time_str):\n",
    "    \"\"\"Convert GTFS time string (HH:MM:SS) to UTC datetime, handling times > 24:00\"\"\"\n",
    "    from datetime import datetime, timedelta\n",
    "    import pytz\n",
    "\n",
    "    if not time_str or pd.isna(time_str):\n",
    "        return None\n",
    "\n",
    "    # Parse the time string\n",
    "    hours, minutes, seconds = map(int, time_str.split(':'))\n",
    "\n",
    "    # Calculate days to add (for times > 24:00)\n",
    "    extra_days = hours // 24\n",
    "    hours = hours % 24\n",
    "\n",
    "    # Create base datetime for service date\n",
    "    base_date = datetime(service_date // 10000, (service_date % 10000) // 100, service_date % 100)\n",
    "\n",
    "    # Add the time\n",
    "    dt = base_date + timedelta(days=extra_days, hours=hours, minutes=minutes, seconds=seconds)\n",
    "\n",
    "    # Assume local timezone (you may need to adjust this based on your GTFS feed's timezone)\n",
    "    local_tz = pytz.timezone('Pacific/Auckland')  # Adjust for your timezone\n",
    "    dt_local = local_tz.localize(dt)\n",
    "\n",
    "    # Convert to UTC\n",
    "    dt_utc = dt_local.astimezone(pytz.UTC)\n",
    "\n",
    "    return dt_utc\n",
    "\n",
    "if not trips_df.empty and APPLICABLE_FEED_HASH:\n",
    "    # Get ALL stop times for this feed (no filtering in SQL)\n",
    "    stop_times_query = f\"\"\"\n",
    "    SELECT\n",
    "        st.trip_id, st.stop_id, st.stop_sequence, s.stop_code, s.stop_name, st.stop_headsign, st.arrival_time, st.departure_time,\n",
    "        s.stop_lat, s.stop_lon, st.shape_dist_traveled\n",
    "    FROM `{PROJECT_ID}.{DATASET}.sc_stop_times` st\n",
    "    LEFT JOIN `{PROJECT_ID}.{DATASET}.sc_stops` s\n",
    "    ON st.stop_id = s.stop_id AND st.feed_hash = s.feed_hash\n",
    "    WHERE st.feed_hash = '{APPLICABLE_FEED_HASH}'\n",
    "    \"\"\"\n",
    "    stop_times_df = client.query(stop_times_query).to_dataframe()\n",
    "\n",
    "    # Convert times to UTC format with shorter field names\n",
    "    stop_times_df['arrival'] = stop_times_df['arrival_time'].apply(\n",
    "        lambda x: convert_gtfs_time_to_utc(SERVICE_DATE, x)\n",
    "    )\n",
    "    stop_times_df['departure'] = stop_times_df['departure_time'].apply(\n",
    "        lambda x: convert_gtfs_time_to_utc(SERVICE_DATE, x)\n",
    "    )\n",
    "    stop_times_df['arrival_s'] = stop_times_df['arrival'].apply(\n",
    "        lambda x: int(x.timestamp()) if x else None\n",
    "    )\n",
    "    stop_times_df['departure_s'] = stop_times_df['departure'].apply(\n",
    "        lambda x: int(x.timestamp()) if x else None\n",
    "    )\n",
    "\n",
    "    # Join with trips data in pandas\n",
    "    schedule_df = stop_times_df.merge(trips_df, on='trip_id', how='inner')\n",
    "\n",
    "    logger.info(f\"Stop times: {len(stop_times_df)}\")\n",
    "    logger.info(f\"Schedule entries: {len(schedule_df)}\")\n",
    "else:\n",
    "    stop_times_df = pd.DataFrame()\n",
    "    schedule_df = pd.DataFrame()\n",
    "    logger.info(\"No stop times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28efd8f",
   "metadata": {},
   "source": [
    "# Step 5: Build Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71f296a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Final schedule: 315112 entries\n",
      "INFO - Columns: ['service_date', 'service_id', 'route_id', 'trip_id', 'stop_id', 'stop_sequence', 'route_short_name', 'route_type', 'direction_id', 'trip_headsign', 'stop_code', 'stop_name', 'stop_headsign', 'arrival_time', 'departure_time', 'arrival', 'departure', 'arrival_s', 'departure_s', 'stop_lat', 'stop_lon', 'shape_id', 'shape_dist_traveled']\n",
      "INFO - Columns: ['service_date', 'service_id', 'route_id', 'trip_id', 'stop_id', 'stop_sequence', 'route_short_name', 'route_type', 'direction_id', 'trip_headsign', 'stop_code', 'stop_name', 'stop_headsign', 'arrival_time', 'departure_time', 'arrival', 'departure', 'arrival_s', 'departure_s', 'stop_lat', 'stop_lon', 'shape_id', 'shape_dist_traveled']\n"
     ]
    }
   ],
   "source": [
    "if not schedule_df.empty:\n",
    "    # Add service date and sort the final schedule\n",
    "    schedule_df['service_date'] = SERVICE_DATE\n",
    "    schedule_df = schedule_df.sort_values(['route_short_name', 'direction_id', 'trip_id', 'stop_sequence'])\n",
    "\n",
    "    # Reorder columns in logical groups\n",
    "    logical_column_order = [\n",
    "        # Identity\n",
    "        'service_date', 'service_id', 'route_id','trip_id', 'stop_id', 'stop_sequence',\n",
    "\n",
    "        # Route info\n",
    "        'route_short_name', 'route_type', 'direction_id',\n",
    "\n",
    "        # Trip info\n",
    "        'trip_headsign',\n",
    "\n",
    "        # Stop info\n",
    "        'stop_code', 'stop_name', 'stop_headsign',\n",
    "\n",
    "        # Time fields (original GTFS + converted)\n",
    "        'arrival_time', 'departure_time', 'arrival', 'departure', 'arrival_s', 'departure_s',\n",
    "\n",
    "        # Other\n",
    "        'stop_lat', 'stop_lon', 'shape_id', 'shape_dist_traveled'\n",
    "    ]\n",
    "\n",
    "    # Only include columns that actually exist\n",
    "    existing_columns = [col for col in logical_column_order if col in schedule_df.columns]\n",
    "    schedule_df = schedule_df[existing_columns]\n",
    "\n",
    "    logger.info(f\"Final schedule: {len(schedule_df)} entries\")\n",
    "    logger.info(f\"Columns: {list(schedule_df.columns)}\")\n",
    "else:\n",
    "    schedule_df = pd.DataFrame()\n",
    "    logger.info(\"No schedule data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca7c483b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['service_date', 'service_id', 'route_id', 'trip_id', 'stop_id',\n",
       "       'stop_sequence', 'route_short_name', 'route_type', 'direction_id',\n",
       "       'trip_headsign', 'stop_code', 'stop_name', 'stop_headsign',\n",
       "       'arrival_time', 'departure_time', 'arrival', 'departure', 'arrival_s',\n",
       "       'departure_s', 'stop_lat', 'stop_lon', 'shape_id',\n",
       "       'shape_dist_traveled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86a70251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "33453",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "7e67f419-e96f-4960-b1b9-21abb4e80c32",
       "rows": [
        [
         "service_date",
         "20250914"
        ],
        [
         "service_id",
         "Sunday-1"
        ],
        [
         "route_id",
         "105-202"
        ],
        [
         "trip_id",
         "1255-10501-22500-2-4d9a247b"
        ],
        [
         "stop_id",
         "8496-67820052"
        ],
        [
         "stop_sequence",
         "1"
        ],
        [
         "route_short_name",
         "105"
        ],
        [
         "route_type",
         "3"
        ],
        [
         "direction_id",
         "0"
        ],
        [
         "trip_headsign",
         "Westmere To Britomart Via Richmond Rd"
        ],
        [
         "stop_code",
         "8496"
        ],
        [
         "stop_name",
         "Cox's Bay Reserve"
        ],
        [
         "stop_headsign",
         "BRITOMART"
        ],
        [
         "arrival_time",
         "06:15:00"
        ],
        [
         "departure_time",
         "06:15:00"
        ],
        [
         "arrival",
         "2025-09-13 18:15:00+00:00"
        ],
        [
         "departure",
         "2025-09-13 18:15:00+00:00"
        ],
        [
         "arrival_s",
         "1757787300"
        ],
        [
         "departure_s",
         "1757787300"
        ],
        [
         "stop_lat",
         "-36.85176"
        ],
        [
         "stop_lon",
         "174.72277"
        ],
        [
         "shape_id",
         "1255-10501-f6eb24e2"
        ],
        [
         "shape_dist_traveled",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 23
       }
      },
      "text/plain": [
       "service_date                                        20250914\n",
       "service_id                                          Sunday-1\n",
       "route_id                                             105-202\n",
       "trip_id                          1255-10501-22500-2-4d9a247b\n",
       "stop_id                                        8496-67820052\n",
       "stop_sequence                                              1\n",
       "route_short_name                                         105\n",
       "route_type                                                 3\n",
       "direction_id                                               0\n",
       "trip_headsign          Westmere To Britomart Via Richmond Rd\n",
       "stop_code                                               8496\n",
       "stop_name                                  Cox's Bay Reserve\n",
       "stop_headsign                                      BRITOMART\n",
       "arrival_time                                        06:15:00\n",
       "departure_time                                      06:15:00\n",
       "arrival                            2025-09-13 18:15:00+00:00\n",
       "departure                          2025-09-13 18:15:00+00:00\n",
       "arrival_s                                         1757787300\n",
       "departure_s                                       1757787300\n",
       "stop_lat                                           -36.85176\n",
       "stop_lon                                           174.72277\n",
       "shape_id                                 1255-10501-f6eb24e2\n",
       "shape_dist_traveled                                      0.0\n",
       "Name: 33453, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7623a6",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Built daily schedule from GTFS data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
